---
title: 用多种方法爬取超美的壁纸网站（二）
tags:
  - Python
  - 壁纸
  - 爬虫
  - 脚本
id: '81'
categories:
  - - 编程学习
date: 2017-04-14 19:37:51
---

![](https://cdn.pixabay.com/photo/2016/02/14/09/45/precious-1199183__480.jpg) 继续接着上篇文章介绍如何利用另外两种方式爬取 Simple Desktop 网站的壁纸。
<!-- more -->
这个方法我们要使用pyquery库，如果没有安装先要使用pip安装。

```bash
pip install pyquery
```

> 使用pyquery css选择器爬取

使用这个库就要对CSS选择器有一定了解，超简单介绍一下，详细可以看官方文档。

> 使用CSS选择器记住三点： 1.`class`使用`.` 2.`id`使用`#` 3.`tag`直接写

这样应该就能看懂下边代码的定位部分了。

```python
from pyquery import PyQuery as pq
from multiprocessing import Pool
import re
import pymongo

def get_index_page(url):
    doc = pq(url)
    if doc:
        titles = doc('.desktop a img').items()
        photos = doc('.desktop a img').items()
        for title, photo in zip(titles, photos):
            yield {
                "title": title.attr.title,
                "url":parse_page(photo.attr.src)
            }

def parse_page(html):
    pattern = re.compile('(.*?).295x184_q100.png')
    items = re.findall(pattern, html)
    for item in items:
        return item

def save_to_mongo(infos):
    client = pymongo.MongoClient()
    db = client['photos']
    infors = db['wallpaper']
    infors.insert(infos)

def main(page):
    url = "http://simpledesktops.com/browse/{}/".format(page)
    for infos in get_index_page(url):
        try:
            save_to_mongo(infos)
            print("Success!")
        except BaseException as e:
            print("False", e)
            break

if __name__ == '__main__':
    p = Pool()
    try:
    p.map(main, [page for page in range(1,51)])
    except BaseException as e:
    print("Error! ",e)
```

这段代码同时实现了存储到Mongo数据库中。 还有一种方法是使用xpath定位，这段代码实现了保存到本地文件夹。

> 利用xpath爬取

```python
from lxml import etree
from multiprocessing import Pool
from urllib.request import urlopen
import requests
import re

def get_page(url):
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    return None

def parse_page(html):
    response = etree.HTML(html)
    items = response.xpath("/html/body/div/div[2]/div/div[2]")
    for item in items:
        titles = item.xpath('.//div/div/a/img/@title')
        urls = item.xpath('.//div/div/a/img/@src')
        for title, url in zip(titles, urls):
            if url is not None:
                print("Title: {}\nUrl: {}\n".format(title, re_page(url)))
                download(title, re_page(url))
                print("保存成功")

def re_page(html):
    pattern = re.compile('(.*?).295x184_q100.png')
    items = re.findall(pattern, html)
    for item in items:
        return item

def download(title, url):
    with open("/home/alpha/PycharmProjects/bizhi/wallpaper/" + str(title) + ".png", 'wb') as f:
        if url is not None:
            wallpaper = urlopen(url).read()
            f.write(wallpaper)

def main(page):
    url = "http://simpledesktops.com/browse/{}/".format(page)
    html = get_page(url)
    parse_page(html)

if __name__ == '__main__':
    pool = Pool()
    pool.map(main, [page for page in range(1, 51)])
```

在保存文件的过程中才发现有些壁纸只有标题没有URL，所以在爬取到某些地方时会报错，用if判断一下就好了。 在命名的时候写为绝对路径，保存的时候就会保存到对应文件夹中。